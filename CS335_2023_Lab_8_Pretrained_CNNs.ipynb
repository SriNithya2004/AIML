{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82476c3",
      "metadata": {
        "id": "f82476c3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FkIQ2BTdmNGc"
      },
      "id": "FkIQ2BTdmNGc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.use_deterministic_algorithms(True, warn_only=True)\n",
        "\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n"
      ],
      "metadata": {
        "id": "7geIp0evzEfr"
      },
      "id": "7geIp0evzEfr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/scl/fi/w22pt8h447b9ptgql67vo/dataset.tar.gz?rlkey=vajo7g4w8nl1q92ikv8qu75qu&dl=0"
      ],
      "metadata": {
        "id": "QF36u8ne2gJi"
      },
      "id": "QF36u8ne2gJi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv dataset.tar.gz?rlkey=vajo7g4w8nl1q92ikv8qu75qu dataset.tar.gz"
      ],
      "metadata": {
        "id": "5H-zc_z0dL-E"
      },
      "id": "5H-zc_z0dL-E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32851d0b",
      "metadata": {
        "id": "32851d0b"
      },
      "outputs": [],
      "source": [
        "!tar -xzvf dataset.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "print(\"device is {}\".format(device))"
      ],
      "metadata": {
        "id": "8TyKKrtvq7An"
      },
      "id": "8TyKKrtvq7An",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e610d1d",
      "metadata": {
        "id": "8e610d1d"
      },
      "outputs": [],
      "source": [
        "def read_image_tensor(image_folder,transform,num_images=None):\n",
        "    if num_images==None:\n",
        "        num_images = len(os.listdir(image_folder))\n",
        "    images = []\n",
        "    for i in range(num_images):\n",
        "        img = torchvision.io.read_image(os.path.join(image_folder,f\"{i}.jpg\")).float()\n",
        "        images.append(transform(img))\n",
        "    return torch.stack(images).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "451ab492",
      "metadata": {
        "id": "451ab492"
      },
      "outputs": [],
      "source": [
        "def get_labels(csv_file):\n",
        "    # TODO: Copy this from the Colab notebook in Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "673f056d",
      "metadata": {
        "id": "673f056d"
      },
      "outputs": [],
      "source": [
        "img_size = (256,256)\n",
        "base_transform = transforms.Compose(\n",
        "    [transforms.Resize(img_size)\n",
        "    ]\n",
        ")\n",
        "train_X = read_image_tensor(\"dataset/train/\",base_transform)/256\n",
        "train_Y = get_labels(\"dataset/train.csv\")\n",
        "valid_X = read_image_tensor(\"dataset/test/\",base_transform)/256\n",
        "valid_Y = get_labels(\"dataset/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(train_X, train_Y)\n",
        "valid_dataset = TensorDataset(valid_X, valid_Y)\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "bfMM0sWT5Q76"
      },
      "id": "bfMM0sWT5Q76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can use this utility function to get the number of trainable parameters in your model\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "1x_fF1OUWVQS"
      },
      "id": "1x_fF1OUWVQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "# TODO: Load a pretrained model VGG-11 into baseModel\n",
        "# Refer to https://pytorch.org/docs/stable/hub.html#torch.hub.load on how to load a pretrained vgg11 model\n",
        "# VGG model: https://pytorch.org/hub/pytorch_vision_vgg/\n",
        "baseModel = None\n",
        "baseModel = #TODO: Complete definition\n",
        "\n",
        "# TODO: Freeze all the params of the VGG-11 model\n",
        "# Make sure that gradients are not backpropagated through the VGG-11 model\n",
        "\n",
        "# Once frozen correctly, the following statement should print that the number of trainable params is 0\n",
        "print(\"Number of trainable params in base model is \", count_parameters(baseModel))"
      ],
      "metadata": {
        "id": "Vlz2BiFFqEXN"
      },
      "id": "Vlz2BiFFqEXN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the classifier which will use the pretrained VGG-11 model's features as input\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "  def __init__(self, baseModel, numOutputNeurons):\n",
        "    super().__init__()\n",
        "\t  # initialize the base model\n",
        "\n",
        "    self.baseModel = baseModel\n",
        "    self.baseModel.classifier =\n",
        "      #TODO: Complete this definition\n",
        "      # Add a linear layer to project down to 1024 nodes, followed by ReLU, a dropout layer with p = 0.5 and another linear layer\n",
        "      # projecting the 1024 nodes down to numOutputNeurons (= 1 in our problem)\n",
        "      # Finally, a sigmoid layer is added for the output probabilities\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO: Complete forward definition\n",
        "    # TODO: return the classifier's output probabilities saved in probs\n",
        "    return probs\n"
      ],
      "metadata": {
        "id": "3CU42f87aLN5"
      },
      "id": "3CU42f87aLN5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(device)\n",
        "model = None\n",
        "model = Classifier(baseModel=baseModel, numOutputNeurons=1)\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model is \")\n",
        "print(model)\n",
        "print(\"Trainable params of new model with classifier head is \", count_parameters(model))"
      ],
      "metadata": {
        "id": "tXk73h3gaN4e"
      },
      "id": "tXk73h3gaN4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize loss function and optimizer\n",
        "num_epochs = 30\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "Q4M72SJFrwtn"
      },
      "id": "Q4M72SJFrwtn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, valid_loader, num_epochs, loss_function, optimizer):\n",
        "    # TODO: Note how the best checkpoint is saved based on validation accuracy\n",
        "\n",
        "    set_seed(42)\n",
        "    prev_acc = 0.0\n",
        "    best_checkpoint = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        total_loss = 0.0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "\n",
        "            loss = loss_function(output, labels.view(output.shape))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        average_loss = total_loss/len(train_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}\")\n",
        "        model.eval()\n",
        "\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in valid_loader:\n",
        "                inputs, labels = data\n",
        "                outputs = model(inputs)\n",
        "                pred = (outputs > 0.5)*1\n",
        "                correct += (pred==labels.view(pred.shape)).sum()\n",
        "                total += labels.size(0)\n",
        "            accur = 100*correct/total\n",
        "            print(f\"Test Accuracy after Epoch {epoch+1}: {accur:.2f}%\")\n",
        "            if accur > prev_acc:\n",
        "              print(\"Saving best checkpoint\")\n",
        "              prev_acc = accur\n",
        "              best_checkpoint = copy.deepcopy(model)\n",
        "\n",
        "\n",
        "    print(\"Training done.\")\n",
        "    return best_checkpoint"
      ],
      "metadata": {
        "id": "8ZMr7_SfuA1C"
      },
      "id": "8ZMr7_SfuA1C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_checkpoint = train_model(model, train_loader, valid_loader, num_epochs, loss_func, optimizer)"
      ],
      "metadata": {
        "id": "WFtKlVk6iGiQ"
      },
      "id": "WFtKlVk6iGiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "\n",
        "  set_seed(42)\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "\n",
        "  # TODO: Evaluate model and generate binary outputs for all the test instances\n",
        "  # in test_loader. Return the predicted outputs in a list named predictions.\n",
        "  return predictions\n"
      ],
      "metadata": {
        "id": "ZQ2hEJ9flxCb"
      },
      "id": "ZQ2hEJ9flxCb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate using best checkpoint on Kaggle test set"
      ],
      "metadata": {
        "id": "57VUDxpnkzRI"
      },
      "id": "57VUDxpnkzRI"
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (256,256)\n",
        "base_transform = transforms.Compose(\n",
        "    [transforms.Resize(img_size)\n",
        "    ]\n",
        ")\n",
        "kaggle_X = read_image_tensor(\"dataset/kaggle/\",base_transform)/256\n",
        "kaggle_dataset = TensorDataset(kaggle_X)\n",
        "batch_size = 64\n",
        "\n",
        "kaggle_loader = DataLoader(kaggle_dataset, batch_size=batch_size, shuffle=False)\n",
        "kaggle_predictions = evaluate(best_checkpoint, kaggle_loader)\n",
        "\n",
        "ids = [i for i in range(len(kaggle_predictions))]\n",
        "pred_dict = {\"id\": ids, \"label\": kaggle_predictions}\n",
        "df = pd.DataFrame(pred_dict)\n",
        "df.to_csv(\"./submission.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "quiiTK9BkycQ"
      },
      "id": "quiiTK9BkycQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the last few layers of vgg-11 along with the classifier"
      ],
      "metadata": {
        "id": "J665ldu5E0mT"
      },
      "id": "J665ldu5E0mT"
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "baseModel = None\n",
        "# TODO: Copy from an earlier cell where baseModel is initialized to a pretrained VGG-11"
      ],
      "metadata": {
        "id": "KT-sxHnVDpuz"
      },
      "id": "KT-sxHnVDpuz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_parameters(baseModel))\n",
        "\n",
        "# TODO: Except for parameters in the last layer or two, freeze the rest.\n",
        "# The two print statements will show the initial number of trainable parameters\n",
        "# in baseModel and the substantially smaller (almost by a factor of 100)\n",
        "# number of trainable parameters after implementing the TODO.\n",
        "\n",
        "print(count_parameters(baseModel))"
      ],
      "metadata": {
        "id": "aYYX6lvcWcD1"
      },
      "id": "aYYX6lvcWcD1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(device)\n",
        "model = None\n",
        "model = Classifier(baseModel=baseModel, numOutputNeurons=1)\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model is \")\n",
        "print(model)\n",
        "print(\"Trainable params of new model with classifier head is \", count_parameters(model))"
      ],
      "metadata": {
        "id": "Ekpot74OhW9E"
      },
      "id": "Ekpot74OhW9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize loss function and optimizer\n",
        "num_epochs = 30\n",
        "loss_func = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "ds_or9LkLq9S"
      },
      "id": "ds_or9LkLq9S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_checkpoint_ft = train_model(model, train_loader, valid_loader, num_epochs, loss_func, optimizer)"
      ],
      "metadata": {
        "id": "dNxiSyQHktW6"
      },
      "id": "dNxiSyQHktW6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "kaggle_loader = DataLoader(kaggle_dataset, batch_size=batch_size, shuffle=False)\n",
        "kaggle_predictions = evaluate(best_checkpoint_ft, kaggle_loader)\n",
        "\n",
        "ids = [i for i in range(len(kaggle_predictions))]\n",
        "pred_dict = {\"id\": ids, \"label\": kaggle_predictions}\n",
        "df = pd.DataFrame(pred_dict)\n",
        "df.to_csv(\"./submission.csv\", index=False)\n",
        "\n",
        "# Submit submission.csv to Kaggle"
      ],
      "metadata": {
        "id": "gv-bsFG4kvtC"
      },
      "id": "gv-bsFG4kvtC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}